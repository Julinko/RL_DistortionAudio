{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning für Verzerrer-Parameteroptimierung\n",
    "\n",
    "In diesem Jupyter-Notebook verwenden wir Q-Learning, um die optimalen Parameter für einen Verzerrer zu finden. Der Code ist in verschiedene Sektionen unterteilt:\n",
    "\n",
    "**1. Einrichtung und Initialisierung**\n",
    "- **Bibliotheken**: Import von notwendigen Bibliotheken wie `numpy` und `scipy`.\n",
    "\n",
    "**2. DistortionParameters-Klasse**\n",
    "- **Zweck**: Repräsentiert die Parameter des Verzerrers: `Gain`, `Tone` und `Level`.\n",
    "- **Methoden**: Zum Setzen und Abrufen dieser Parameter.\n",
    "\n",
    "**3. Environment-Klasse: Verzerrer und Signal**\n",
    "- **Signal**: Generiert ein Sinussignal und verarbeitet es mit dem Verzerrer.\n",
    "- **Verarbeitung**: Methoden wie `_apply_gain`, `_apply_tone` und `_apply_level`.\n",
    "\n",
    "**4. Q-Learning-Agent-Klasse**\n",
    "- **Algorithmus**: Implementiert den Q-Learning-Algorithmus.\n",
    "- **Q-Tabelle**: Wird zum Lernen der besten Aktionen (Parameter) verwendet.\n",
    "- **Methoden**: Zum Wählen von Aktionen und Aktualisieren der Q-Tabelle.\n",
    "\n",
    "**5. Training**\n",
    "- **Prozess**: Trainiert den Q-Learning-Agenten über mehrere Episoden.\n",
    "- **Belohnung**: In jeder Episode wird das Signal verarbeitet und eine Belohnung basierend auf dem Unterschied zum Ziel-Ausgangssignal berechnet.\n",
    "\n",
    "**6. Ergebnisse**\n",
    "- **Ausgabe**: Zeigt die gelernten optimalen Parameter nach dem Training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sektion 1: Einrichtung und Initialisierung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from IPython.display import Audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sektion 2: DistortionParameters-Klasse**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DistortionParameters:\n",
    "    def __init__(self, gain=0.5, tone=0.5, level=0.5):\n",
    "        self.gain = gain\n",
    "        self.tone = tone\n",
    "        self.level = level\n",
    "    \n",
    "    def set_parameters(self, gain, tone, level):\n",
    "        self.gain = gain\n",
    "        self.tone = tone\n",
    "        self.level = level\n",
    "        \n",
    "    def get_parameters(self):\n",
    "        return self.gain, self.tone, self.level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sektion 3: Environment-Klasse: Verzerrer und Signal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistortionEnvironment:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.signal = self._generate_signal()\n",
    "        self.target_signal = self.process(self.signal)\n",
    "    \n",
    "    def _generate_signal(self):\n",
    "        t = np.linspace(0, 1, 44100)\n",
    "        return np.sin(2 * np.pi * 440 * t)\n",
    "    \n",
    "    def process(self, signal):\n",
    "        return self._apply_level(self._apply_tone(self._apply_gain(signal, self.params.gain), self.params.tone), self.params.level)\n",
    "    \n",
    "    def _apply_gain(self, signal, gain):\n",
    "        return np.clip(signal * gain, -1, 1)\n",
    "    \n",
    "    def _apply_tone(self, signal, tone):\n",
    "        nyq = 0.5 * 44100\n",
    "        low = 300\n",
    "        high = 6000\n",
    "        cutoff = low + (high - low) * tone\n",
    "        b, a = butter(1, cutoff / nyq, btype='low')\n",
    "        return lfilter(b, a, signal)\n",
    "    \n",
    "    def _apply_level(self, signal, level):\n",
    "        return signal * level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sektion 3: Environment-Klasse: Verzerrer und Signal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.2):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_table = np.zeros((11, 11, 11))\n",
    "    \n",
    "    def choose_action(self):\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            return np.random.rand(3)  # Random Action\n",
    "        else:\n",
    "            indices = np.unravel_index(np.argmax(self.q_table, axis=None), self.q_table.shape)  # Greedy Action\n",
    "            return indices[0] / 10, indices[1] / 10, indices[2] / 10\n",
    "    \n",
    "    def update(self, state, reward):\n",
    "        future_value = np.max(self.q_table)\n",
    "        index = tuple((np.array(state) * 10).astype(int))\n",
    "        self.q_table[index] = (\n",
    "            self.q_table[index] + \n",
    "            self.alpha * (reward + self.gamma * future_value - self.q_table[index])\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sektion 5: Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = DistortionParameters(np.random.rand(), np.random.rand(), np.random.rand())\n",
    "env = DistortionEnvironment(params)\n",
    "agent = QLearningAgent()\n",
    "\n",
    "def reward_function(output_signal, target_signal):\n",
    "    return -np.mean((output_signal - target_signal) ** 2)\n",
    "\n",
    "for episode in range(50000):\n",
    "    action = agent.choose_action()\n",
    "    params.set_parameters(*action)\n",
    "    output_signal = env.process(env.signal)\n",
    "    reward = reward_function(output_signal, env.target_signal)\n",
    "    agent.update(action, reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sektion 6: Ergebnisse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Echte Parameter - Gain: 0.5 Tone: 0.1 Level: 1.0\n",
      "Gelernte Parameter - Gain: 0.5 Tone: 0.1 Level: 1.0\n"
     ]
    }
   ],
   "source": [
    "optimal_indices = np.unravel_index(np.argmax(agent.q_table, axis=None), agent.q_table.shape)\n",
    "optimal_params = DistortionParameters(optimal_indices[0] / 10, optimal_indices[1] / 10, optimal_indices[2] / 10)\n",
    "\n",
    "print(\"Echte Parameter - Gain:\", params.gain, \"Tone:\", params.tone, \"Level:\", params.level)\n",
    "print(\"Gelernte Parameter - Gain:\", optimal_params.gain, \"Tone:\", optimal_params.tone, \"Level:\", optimal_params.level)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
